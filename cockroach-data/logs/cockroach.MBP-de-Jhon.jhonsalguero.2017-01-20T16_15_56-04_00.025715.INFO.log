I170120 16:15:56.559074 1 util/log/clog.go:1003  [config] file created at: 2017/01/20 16:15:56
I170120 16:15:56.559074 1 util/log/clog.go:1003  [config] running on machine: MBP-de-Jhon
I170120 16:15:56.559074 1 util/log/clog.go:1003  [config] binary: CockroachDB beta-20170112 (darwin amd64, built 2017/01/20 15:39:54, go1.7.4)
I170120 16:15:56.559074 1 util/log/clog.go:1003  [config] arguments: [cockroach start --http-port=8000]
I170120 16:15:56.559074 1 util/log/clog.go:1003  line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg
I170120 16:15:56.559074 1 cli/start.go:320  CockroachDB beta-20170112 (darwin amd64, built 2017/01/20 15:39:54, go1.7.4)
I170120 16:15:56.660518 1 cli/start.go:336  starting cockroach node
W170120 16:15:56.663011 1 server/server.go:156  [n?] running in insecure mode, this is strongly discouraged. See --insecure.
W170120 16:15:56.666824 1 server/config.go:322  soft open file descriptor limit 10240 is under the recommended limit 15000; this may decrease performance
please see https://www.cockroachlabs.com/docs/recommended-production-settings.html for more details
I170120 16:15:56.666860 1 storage/engine/rocksdb.go:326  opening rocksdb instance at "cockroach-data"
I170120 16:15:56.671916 1 server/config.go:456  1 storage engine initialized
I170120 16:15:56.672432 1 server/node.go:426  [n?] store [n0,s0] not bootstrapped
I170120 16:15:56.674856 1 server/node.go:355  [n?] **** cluster ac4ddf54-7828-43de-a2ff-b3a6633f1ccb has been created
I170120 16:15:56.674879 1 server/node.go:356  [n?] **** add additional nodes by specifying --join=localhost:26257
I170120 16:15:56.675452 1 storage/store.go:1237  [n1] [n1,s1]: failed initial metrics computation: [n1,s1]: system config not yet available
I170120 16:15:56.675766 1 server/node.go:439  [n1] initialized store [n1,s1]: {Capacity:249788112896 Available:149708365824 RangeCount:1 LeaseCount:0}
I170120 16:15:56.675789 1 server/node.go:324  [n1] node ID 1 initialized
I170120 16:15:56.675866 1 gossip/gossip.go:292  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"localhost:26257" > attrs:<> locality:<> 
I170120 16:15:56.675916 1 storage/stores.go:296  [n1] read 0 node addresses from persistent storage
I170120 16:15:56.675989 1 server/node.go:569  [n1] connecting to gossip network to verify cluster ID...
I170120 16:15:56.676001 1 server/node.go:589  [n1] node connected via gossip and verified as part of cluster "ac4ddf54-7828-43de-a2ff-b3a6633f1ccb"
I170120 16:15:56.676025 1 server/node.go:374  [n1] node=1: started with [[]=cockroach-data] engine(s) and attributes []
I170120 16:15:56.676055 1 sql/executor.go:322  [n1] creating distSQLPlanner with address {tcp localhost:26257}
I170120 16:15:56.676587 121 storage/split_queue.go:99  [split,n1,s1,r1/1:/M{in-ax},@c420400000] splitting at keys [/Table/11/0 /Table/12/0 /Table/13/0 /Table/14/0]
I170120 16:15:56.678564 121 storage/replica_command.go:2362  [split,n1,s1,r1/1:/M{in-ax},@c420400000] initiating a split of this range at key /Table/11 [r2]
I170120 16:15:56.679139 1 server/server.go:621  [n1] starting http server at localhost:8000
I170120 16:15:56.679150 1 server/server.go:622  [n1] starting grpc/postgres server at localhost:26257
I170120 16:15:56.679159 1 server/server.go:623  [n1] advertising CockroachDB node at localhost:26257
I170120 16:15:56.684042 105 sql/event_log.go:95  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:{NetworkField:tcp AddressField:localhost:26257} Attrs: Locality:} ClusterID:ac4ddf54-7828-43de-a2ff-b3a6633f1ccb StartedAt:1484943356676004454}
E170120 16:15:56.688785 121 storage/queue.go:599  [split,n1,s1,r1/1:/{Min-Table/11},@c420400000] unable to split [n1,s1,r1/1:/{Min-Table/11}] at key "/Table/12/0": key range /Table/12/0-/Table/12/0 outside of bounds of range /Min-/Max
E170120 16:15:56.689126 122 storage/queue.go:610  [replicate,n1,s1,r1/1:/{Min-Table/11},@c420400000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I170120 16:15:56.689179 121 storage/split_queue.go:99  [split,n1,s1,r2/1:/{Table/11-Max},@c4209a0f00] splitting at keys [/Table/12/0 /Table/13/0 /Table/14/0]
I170120 16:15:56.689199 121 storage/replica_command.go:2362  [split,n1,s1,r2/1:/{Table/11-Max},@c4209a0f00] initiating a split of this range at key /Table/12 [r3]
E170120 16:15:56.689210 61 storage/queue.go:610  [replicate,n1,s1,r1/1:/{Min-Table/11},@c420400000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I170120 16:15:56.691110 1 sql/event_log.go:95  [n1] Event: "alter_table", target: 12, info: {TableName:eventlog Statement:ALTER TABLE system.eventlog ALTER COLUMN uniqueID SET DEFAULT uuid_v4() User:node MutationID:0 CascadeDroppedViews:[]}
E170120 16:15:56.692592 122 storage/queue.go:610  [replicate,n1,s1,r2/1:/Table/1{1-2},@c4209a0f00] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.692635 61 storage/queue.go:610  [replicate,n1,s1,r1/1:/{Min-Table/11},@c420400000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.692669 121 storage/queue.go:599  [split,n1,s1,r2/1:/Table/1{1-2},@c4209a0f00] unable to split [n1,s1,r2/1:/Table/1{1-2}] at key "/Table/13/0": key range /Table/13/0-/Table/13/0 outside of bounds of range /Table/11-/Max
I170120 16:15:56.692731 121 storage/split_queue.go:99  [split,n1,s1,r3/1:/{Table/12-Max},@c420b08300] splitting at keys [/Table/13/0 /Table/14/0]
I170120 16:15:56.692746 121 storage/replica_command.go:2362  [split,n1,s1,r3/1:/{Table/12-Max},@c420b08300] initiating a split of this range at key /Table/13 [r4]
E170120 16:15:56.696151 122 storage/queue.go:610  [replicate,n1,s1,r3/1:/Table/1{2-3},@c420b08300] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.696219 61 storage/queue.go:610  [replicate,n1,s1,r2/1:/Table/1{1-2},@c4209a0f00] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.696241 121 storage/queue.go:599  [split,n1,s1,r3/1:/Table/1{2-3},@c420b08300] unable to split [n1,s1,r3/1:/Table/1{2-3}] at key "/Table/14/0": key range /Table/14/0-/Table/14/0 outside of bounds of range /Table/12-/Max
E170120 16:15:56.696262 61 storage/queue.go:610  [replicate,n1,s1,r1/1:/{Min-Table/11},@c420400000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I170120 16:15:56.696302 121 storage/split_queue.go:99  [split,n1,s1,r4/1:/{Table/13-Max},@c420811200] splitting at keys [/Table/14/0]
I170120 16:15:56.696336 121 storage/replica_command.go:2362  [split,n1,s1,r4/1:/{Table/13-Max},@c420811200] initiating a split of this range at key /Table/14 [r5]
I170120 16:15:56.697852 1 server/server.go:676  [n1] done ensuring all necessary migrations have run
I170120 16:15:56.697870 1 server/server.go:678  [n1] serving sql connections
E170120 16:15:56.700860 122 storage/queue.go:610  [replicate,n1,s1,r4/1:/Table/1{3-4},@c420811200] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.700906 61 storage/queue.go:610  [replicate,n1,s1,r3/1:/Table/1{2-3},@c420b08300] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.700939 122 storage/queue.go:610  [replicate,n1,s1,r5/1:/{Table/14-Max},@c420b08000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.700979 61 storage/queue.go:610  [replicate,n1,s1,r2/1:/Table/1{1-2},@c4209a0f00] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
E170120 16:15:56.701054 61 storage/queue.go:610  [replicate,n1,s1,r1/1:/{Min-Table/11},@c420400000] purgatory: 0 of 1 store with an attribute matching []; likely not enough nodes in cluster
I170120 16:15:58.439076 1 cli/start.go:397  received signal 'interrupt'
I170120 16:15:58.439131 1 cli/start.go:416  initiating graceful shutdown of server
E170120 16:16:01.846459 1 cli/start.go:438  received signal 'interrupt' during shutdown, initiating hard shutdown
